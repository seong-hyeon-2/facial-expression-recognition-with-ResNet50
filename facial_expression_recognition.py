# -*- coding: utf-8 -*-
"""facial-expression-recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mol9tXrucZ5vOmVKGLvpb9muZyNE5j2A
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# import package

# model
import tensorflow as tf
from tensorflow import keras

# dataset and transformation
import io
import os
import cv2
import math
import glob
from sklearn.model_selection import train_test_split

# display images
import matplotlib.pyplot as plt 
# %matplotlib inline

!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv
!rm ~/.cache/matplotlib -rf

plt.rc('font', family='NanumBarunGothic')

# utils
import numpy as np
import pandas as pd
import time
import copy



# GPU check
!nvidia-smi

# dataset download

# !unzip -qq /content/drive/MyDrive/dataset.zip -d ./dataset
# !cp /content/drive/MyDrive/dataset.csv ./dataset.csv

"""데이터 집어넣기

일단 파일을 드라이브에 넣야합니다. 

그후 파일경로를 밑에 넣으면 됩니다.

"""

# glob - 확장자 파일만 가져온다
# dataset = glob.glob(os.path.join('./dataset', '*.jpg'))
dataset = glob.glob(os.path.join('file_path', '*.jpg'))
print(len(dataset))

"""위 파일들에 해당하는 csv파일을 넣습니다."""

df = pd.read_csv('csv_path')
print(df.__len__())
df.head(5)

xs = np.array(df['path'])
ys = np.array(df['label'])

train_x, valid_x, train_y, valid_y = train_test_split(xs, ys, test_size=0.2)
train_x, test_x, train_y, test_y = train_test_split(xs, ys, test_size=0.2)

train_x = np.array([cv2.imread(item, cv2.IMREAD_GRAYSCALE) / 255 for item in train_x]).reshape(train_x.shape[0], 96, 96, 1)
valid_x = np.array([cv2.imread(item, cv2.IMREAD_GRAYSCALE) / 255 for item in valid_x]).reshape(valid_x.shape[0], 96, 96, 1)
test_x = np.array([cv2.imread(item, cv2.IMREAD_GRAYSCALE) / 255 for item in test_x]).reshape(test_x.shape[0], 96, 96, 1)

train_y = tf.keras.utils.to_categorical(train_y, 5)
valid_y = tf.keras.utils.to_categorical(valid_y, 5)
test_y = tf.keras.utils.to_categorical(test_y, 5)

def show_sample(image, label, sample_count=25):
    grid_count = math.ceil(math.ceil(math.sqrt(sample_count)))
    grid_cout = min(grid_count, len(image), len(label))
    plt.figure(figsize=(2*grid_count, 2*grid_count))

    for i in range(sample_count):
        plt.subplot(grid_count, grid_count, i+1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(image[i].reshape(96, 96), cmap=plt.cm.gray)
        plt.xlabel(label[i], fontsize=14)
    plt.show()

class_to_emotion = {
    '0': 'angry',
    '1': 'happy',
    '2': 'neutral',
    '3': 'sad'
}

show_sample(train_x, [class_to_emotion[str(cls.argmax())] for cls in train_y])

def bottleneck_residual_block(X, filters, reduce=False, s=2):
    F1, F2, F3 = filters
    X_shortcut = X
    
    if reduce:
        X = keras.layers.Conv2D(filters=F1, kernel_size=(1,1), strides=(s,s), padding='valid', kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)
        X = keras.layers.BatchNormalization(axis=3)(X)
        X = keras.layers.ReLU()(X)
        
        X_shortcut = keras.layers.Conv2D(filters=F3, kernel_size=(1,1), strides=(s,s), padding='valid', kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X_shortcut)
        X_shortcut = keras.layers.BatchNormalization(axis=3)(X_shortcut)
    else: 
        X = keras.layers.Conv2D(filters=F1, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)
        X = keras.layers.BatchNormalization(axis=3)(X)
        X = keras.layers.ReLU()(X)
    
    X = keras.layers.Conv2D(filters=F2, kernel_size=(3,3), strides=(1,1), padding='same', kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)
    X = keras.layers.BatchNormalization(axis=3)(X)
    X = keras.layers.ReLU()(X)

    X = keras.layers.Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)
    X = keras.layers.BatchNormalization(axis=3)(X)

    X = keras.layers.Add()([X, X_shortcut])
    X = keras.layers.ReLU()(X)
    
    return X

def ResNet50(classes):
    X_input = keras.layers.Input(shape=[96, 96, 1])

    X = keras.layers.Conv2D(64, (7, 7), strides=(2, 2), kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X_input)
    X = keras.layers.BatchNormalization(axis=3)(X)
    X = keras.layers.ReLU()(X)
    X = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)

    X = bottleneck_residual_block(X, [64, 64, 256], reduce=True, s=1)
    X = bottleneck_residual_block(X, [64, 64, 256])
    X = bottleneck_residual_block(X, [64, 64, 256])

    X = bottleneck_residual_block(X, [128, 128, 512], reduce=True)
    X = bottleneck_residual_block(X, [128, 128, 512])
    X = bottleneck_residual_block(X, [128, 128, 512])
    X = bottleneck_residual_block(X, [128, 128, 512])

    X = bottleneck_residual_block(X, [256, 256, 1024], reduce=True)
    X = bottleneck_residual_block(X, [256, 256, 1024])
    X = bottleneck_residual_block(X, [256, 256, 1024])
    X = bottleneck_residual_block(X, [256, 256, 1024])
    X = bottleneck_residual_block(X, [256, 256, 1024])
    X = bottleneck_residual_block(X, [256, 256, 1024])

    X = bottleneck_residual_block(X, [512, 512, 2048], reduce=True)
    X = bottleneck_residual_block(X, [512, 512, 2048])
    X = bottleneck_residual_block(X, [512, 512, 2048])

    X = keras.layers.AveragePooling2D((1,1))(X)

    X = keras.layers.Flatten()(X)
    X = keras.layers.Dense(units=512, activation='relu')(X)
    X = keras.layers.Dense(units=classes, activation='softmax')(X)
    
    model = keras.models.Model(inputs=X_input, outputs=X)

    return model

# 학습률 0.00005

model = ResNet50(5)
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
model.summary()

# 에폭 50, 배치사이즈 16

start_time = time.time()

callbacks = tf.keras.callbacks.ModelCheckpoint(filepath='model.h5', monitor='val_loss', save_best_only=True)

history = model.fit(
    train_x, train_y, validation_data=(valid_x, valid_y),
    epochs=50, batch_size=16, callbacks=[callbacks]
)

print(f'{time.time() - start_time}초 동안 학습함.')

# 정확도 matplotlib으로 시각화

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# 학습된 모델로 테스트데이터 확인하기

model = keras.models.load_model('model.h5')
pred = model.predict(test_x)

# 결과 보여줌

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    is_correct = 'O' if np.argmax(pred[i]) == np.argmax(test_y[i]) else 'X'
    plt.imshow(test_x.reshape(-1, 96, 96)[i], cmap=plt.cm.gray if np.argmax(pred[i]) == np.argmax(test_y[i]) else None)
    plt.xlabel(f'{class_to_emotion[str(np.argmax(pred[i]))]} ({is_correct})', fontsize=14)
plt.show()

